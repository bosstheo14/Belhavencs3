{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5\n",
    "\n",
    "# Data Manipulation with Pandas\n",
    "\n",
    "In this lab, you'll be working through Chapter 3 to get an introduction to the data manipulation and analysis package for Python, Pandas. This notebook is made up of two sections.\n",
    "\n",
    "- Section 1: Work through the code samples in Chapter 3\n",
    "- Section 2: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Code Practice\n",
    "\n",
    "In this section, you will be reading through the various chapter sections and **typing out**/running the code samples given in the sections. The purpose of this is for you to practice using Jupyter to run Python code as well as learn about the functionality available to you in both IPython and Jupyter.\n",
    "\n",
    "**Do not copy/paste the code**. Type it out. Don't go zen, either. Pay attention to the meaning of what you are typing. Pay attention to the parameters and the types of arguments. Find the similarities and differences among the various object APIs. \n",
    "\n",
    "## The hardest part of Pandas is the *massive* API.\n",
    "\n",
    "The only way to become proficient is to **actually, physically, viscerally** use it. Repeatedly and deliberately over time.\n",
    "\n",
    "---\n",
    "\n",
    "##### Executing code in Jupyter\n",
    "\n",
    "When typing and executing code in Jupyter, it is helpful to know the various keyboard shortcuts. You can find the full list of these by clicking **Help &rarr; Keyboard Shortcuts** in the menu. However, the two most useful keyboard shortcuts are:\n",
    "\n",
    "- `Shift-Enter`: Execute the current cell and advance to the next cell. This will create one if none exists, but if a cell exists below your current cell, a new cell will **not** be created.\n",
    "- `Alt-Enter`: Execute the current cell and **create** a new cell below.\n",
    "- `Control-Enter`: Execute the current cell without advancing to the next cell\n",
    "\n",
    "When writing your code, you will be using these two commands to make sure input/output (`In`/`Out`) is consistent with what is found in the chapter. If you create a cell by mistake, you can always go to **Edit &rarr; Delete Cells** to remove it.\n",
    "\n",
    "#### Purpose of Section 1\n",
    "\n",
    "Your purpose in this section is \n",
    "\n",
    "- **Type out** the code examples from the chapter (do not copy and paste)\n",
    "- **Run** them\n",
    "- **Check** to **make sure** you are getting the same results as what is contained in the chapter\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized String Operations\n",
    "\n",
    "[Chapter/Section link](https://nbviewer.jupyter.org/urls/bitbucket.org/dogwynn/pythondatasciencehandbook/raw/master/notebooks/03.10-Working-With-Strings.ipynb)\n",
    "\n",
    "### Introducing Pandas String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([2, 3, 5, 7, 11, 13])\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables of Pandas String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.startswith('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.extract('([A-Za-z]+)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.findall(r'^[^AEIOU].*[^aeiou]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte.str.split().str.get(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_monte = pd.DataFrame({'name': monte,\n",
    "                           'info': ['B|C|D', 'B|D', 'A|C',\n",
    "                                    'B|D', 'B|C', 'B|C|D']})\n",
    "full_monte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_monte['info'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Recipe Database\n",
    "\n",
    "Do **not** try to execute cell (`In [17]`). The Amazon S3 bucket is empty. Type out and execute the following code instead.\n",
    "\n",
    "```python\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "response = urllib.request.urlopen('https://belhavencs.nyc3.digitaloceanspaces.com/csc311/recipeitems-latest.json.gz')\n",
    "Path('recipeitems-latest.json').write_bytes(gzip.decompress(response.read()))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    recipes = pd.read_json('recipeitems-latest.json')\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('recipeitems-latest.json') as f:\n",
    "    line = f.readline()\n",
    "pd.read_json(line).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the entire file into a Python array\n",
    "with open('recipeitems-latest.json', 'r') as f:\n",
    "    # Extract each line\n",
    "    data = (line.strip() for line in f)\n",
    "    # Reformat so each line is the element of a list\n",
    "    data_json = \"[{0}]\".format(','.join(data))\n",
    "# read the result as a JSON\n",
    "recipes = pd.read_json(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.ingredients.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.name[np.argmax(recipes.ingredients.str.len())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.description.str.contains('[Bb]reakfast').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.ingredients.str.contains('[Cc]innamon').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.ingredients.str.contains('[Cc]inamon').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.ingredients.str.contains('[Cc]inamon').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple recipe recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spice_list = ['salt', 'pepper', 'oregano', 'sage', 'parsley',\n",
    "              'rosemary', 'tarragon', 'thyme', 'paprika', 'cumin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "spice_df = pd.DataFrame(dict((spice, recipes.ingredients.str.contains(spice, re.IGNORECASE))\n",
    "                             for spice in spice_list))\n",
    "spice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selection = spice_df.query('parsley & paprika & tarragon')\n",
    "len(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.name[selection.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Working with Time Series\n",
    "\n",
    "[Chapter/section link](https://nbviewer.jupyter.org/urls/bitbucket.org/dogwynn/pythondatasciencehandbook/raw/master/notebooks/03.11-Working-with-Time-Series.ipynb)\n",
    "\n",
    "### Dates and Times in Python\n",
    "\n",
    "#### Native Python dates and times: `datetime` and `dateutil`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime(year=2015, month=7, day=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "date = parser.parse(\"4th of July, 2015\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date.strftime('%A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typed arrays of times: NumPy's `datetime64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "date = np.array('2015-07-04', dtype=np.datetime64)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date + np.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.datetime64('2015-07-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.datetime64('2015-07-04 12:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.datetime64('2015-07-04 12:59:59.50', 'ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates and times in pandas: best of both worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "date = pd.to_datetime(\"4th of July, 2015\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date.strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date + pd.to_timedelta(np.arange(12), 'D')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Time Series: Indexing by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.DatetimeIndex(['2014-07-04', '2014-08-04',\n",
    "                          '2015-07-04', '2015-08-04'])\n",
    "data = pd.Series([0, 1, 2, 3], index=index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['2014-07-04':'2015-07-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Time Series Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015',\n",
    "                       '2015-Jul-6', '07-07-2015', '20150708'])\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.to_period('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates - dates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular sequences: `pd.date_range()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', '2015-07-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', periods=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.date_range('2015-07-03', periods=8, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.period_range('2015-07', periods=8, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.timedelta_range(0, periods=10, freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies and Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.timedelta_range(0, periods=9, freq=\"2H30T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "pd.date_range('2015-07-01', periods=5, freq=BDay())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling, Shifting, and Windowing\n",
    "\n",
    "You'll need to install a third-party package, `pandas-datareader`, before executing the code in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "\n",
    "goog = data.DataReader('GOOG', start='2004', end='2016',\n",
    "                       data_source='google')\n",
    "goog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goog = goog['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goog.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling and converting frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goog.plot(alpha=0.5, style='-')\n",
    "goog.resample('BA').mean().plot(style=':')\n",
    "goog.asfreq('BA').plot(style='--');\n",
    "plt.legend(['input', 'resample', 'asfreq'],\n",
    "           loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, sharex=True)\n",
    "data = goog.iloc[:10]\n",
    "\n",
    "data.asfreq('D').plot(ax=ax[0], marker='o')\n",
    "\n",
    "data.asfreq('D', method='bfill').plot(ax=ax[1], style='-o')\n",
    "data.asfreq('D', method='ffill').plot(ax=ax[1], style='--o')\n",
    "ax[1].legend([\"back-fill\", \"forward-fill\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, sharey=True)\n",
    "\n",
    "# apply a frequency to the data\n",
    "goog = goog.asfreq('D', method='pad')\n",
    "\n",
    "goog.plot(ax=ax[0])\n",
    "goog.shift(900).plot(ax=ax[1])\n",
    "goog.tshift(900).plot(ax=ax[2])\n",
    "\n",
    "# legends and annotations\n",
    "local_max = pd.to_datetime('2007-11-05')\n",
    "offset = pd.Timedelta(900, 'D')\n",
    "\n",
    "ax[0].legend(['input'], loc=2)\n",
    "ax[0].get_xticklabels()[2].set(weight='heavy', color='red')\n",
    "ax[0].axvline(local_max, alpha=0.3, color='red')\n",
    "\n",
    "ax[1].legend(['shift(900)'], loc=2)\n",
    "ax[1].get_xticklabels()[2].set(weight='heavy', color='red')\n",
    "ax[1].axvline(local_max + offset, alpha=0.3, color='red')\n",
    "\n",
    "ax[2].legend(['tshift(900)'], loc=2)\n",
    "ax[2].get_xticklabels()[1].set(weight='heavy', color='red')\n",
    "ax[2].axvline(local_max + offset, alpha=0.3, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROI = 100 * (goog.tshift(-365) / goog - 1)\n",
    "ROI.plot()\n",
    "plt.ylabel('% Return on Investment');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rolling windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling = goog.rolling(365, center=True)\n",
    "\n",
    "data = pd.DataFrame({'input': goog,\n",
    "                     'one-year rolling_mean': rolling.mean(),\n",
    "                     'one-year rolling_std': rolling.std()})\n",
    "ax = data.plot(style=['-', '--', ':'])\n",
    "ax.lines[0].set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Visualizing Seattle Bicycle Counts\n",
    "\n",
    "Type and execute the following code to load the `FremontBridge.csv` dataset:\n",
    "\n",
    "```python\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "response = urllib.request.urlopen('https://belhavencs.nyc3.digitaloceanspaces.com/csc311/FremontBridge.csv')\n",
    "Path('FremontBridge.csv').write_bytes(response.read())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True)\n",
    "data.head()\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns = ['West', 'East']\n",
    "data['Total'] = data.eval('West + East')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.plot()\n",
    "plt.ylabel('Hourly Bicycle Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekly = data.resample('W').sum()\n",
    "weekly.plot(style=[':', '--', '-'])\n",
    "plt.ylabel('Weekly bicycle count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily = data.resample('D').sum()\n",
    "daily.rolling(30, center=True).sum().plot(style=[':', '--', '-'])\n",
    "plt.ylabel('mean hourly count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily.rolling(50, center=True,\n",
    "              win_type='gaussian').sum(std=10).plot(style=[':', '--', '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digging into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_time = data.groupby(data.index.time).mean()\n",
    "hourly_ticks = 4 * 60 * 60 * np.arange(6)\n",
    "by_time.plot(xticks=hourly_ticks, style=[':', '--', '-']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_weekday = data.groupby(data.index.dayofweek).mean()\n",
    "by_weekday.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\n",
    "by_weekday.plot(style=[':', '--', '-']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "by_time.ix['Weekday'].plot(ax=ax[0], title='Weekdays',\n",
    "                           xticks=hourly_ticks, style=[':', '--', '-'])\n",
    "by_time.ix['Weekend'].plot(ax=ax[1], title='Weekends',\n",
    "                           xticks=hourly_ticks, style=[':', '--', '-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## High-Performance Pandas: `eval()` and `query()`\n",
    "\n",
    "[Chapter/section link](https://nbviewer.jupyter.org/urls/bitbucket.org/dogwynn/pythondatasciencehandbook/raw/master/notebooks/03.12-Performance-Eval-and-Query.ipynb)\n",
    "\n",
    "### Motivating `query()` and `eval()`: Compount Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)\n",
    "x = rng.rand(1000000)\n",
    "y = rng.rand(1000000)\n",
    "%timeit x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit np.fromiter((xi + yi for xi, yi in zip(x, y)), dtype=x.dtype, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (x > 0.5) & (y < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1 = (x > 0.5)\n",
    "tmp2 = (y < 0.5)\n",
    "mask = tmp1 & tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numexpr\n",
    "mask_numexpr = numexpr.evaluate('(x > 0.5) & (y < 0.5)')\n",
    "np.allclose(mask, mask_numexpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas.eval()` for Efficient Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nrows, ncols = 100000, 100\n",
    "rng = np.random.RandomState(42)\n",
    "df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols))\n",
    "                      for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df1 + df2 + df3 + df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval('df1 + df2 + df3 + df4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.allclose(df1 + df2 + df3 + df4,\n",
    "            pd.eval('df1 + df2 + df3 + df4'))\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations supported by `pd.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1, df2, df3, df4, df5 = (pd.DataFrame(rng.randint(0, 1000, (100, 3)))\n",
    "                           for i in range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = -df1 * df2 / (df3 + df4) - df5\n",
    "result2 = pd.eval('-df1 * df2 / (df3 + df4) - df5')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = (df1 < df2) & (df2 <= df3) & (df3 != df4)\n",
    "result2 = pd.eval('df1 < df2 <= df3 != df4')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = (df1 < 0.5) & (df2 < 0.5) | (df3 < df4)\n",
    "result2 = pd.eval('(df1 < 0.5) & (df2 < 0.5) | (df3 < df4)')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result3 = pd.eval('(df1 < 0.5) and (df2 < 0.5) or (df3 < df4)')\n",
    "np.allclose(result1, result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = df2.T[0] + df3.iloc[1]\n",
    "result2 = pd.eval('df2.T[0] + df3.iloc[1]')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.eval()` for Column-Wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rng.rand(1000, 3), columns=['A', 'B', 'C'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = (df['A'] + df['B']) / (df['C'] - 1)\n",
    "result2 = pd.eval(\"(df.A + df.B) / (df.C - 1)\")\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result3 = df.eval('(A + B) / (C - 1)')\n",
    "np.allclose(result1, result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment in `DataFrame.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('D = (A + B) / C', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.eval('D = (A - B) / C', inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local variables in `DataFrame.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_mean = df.mean(1)\n",
    "result1 = df['A'] + column_mean\n",
    "result2 = df.eval('A + @column_mean')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.query()` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = df[(df.A < 0.5) & (df.B < 0.5)]\n",
    "result2 = pd.eval('df[(df.A < 0.5) & (df.B < 0.5)]')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result2 = df.query('A < 0.5 and B < 0.5')\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cmean = df['C'].mean()\n",
    "result1 = df[(df.A < Cmean) & (df.B < Cmean)]\n",
    "result2 = df.query('A < @Cmean and B < @Cmean')\n",
    "np.allclose(result1, result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance: When to Use These Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[(df.A < 0.5) & (df.B < 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1 = df.A < 0.5\n",
    "tmp2 = df.B < 0.5\n",
    "tmp3 = tmp1 & tmp2\n",
    "x = df[tmp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.values.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: Exercises\n",
    "\n",
    "In this section, you will be provided a few exercises to demonstrate your understanding of the chapter contents. Each exercise will have a Markdown section describing the problem, and you will provide cells below the description with code, comments and visual demonstrations of your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use the `seaborn.load_data` function to load the `\"titanic\"` dataset. \n",
    "\n",
    "```python\n",
    "import seaborn\n",
    "titanic = seaborn.load_dataset('titanic')\n",
    "```\n",
    "\n",
    "Using this dataset and the capabilities provided by Pandas, answer the following questions:\n",
    "\n",
    "- What is the impact of being alone on survival rates?\n",
    "- What is the most common embarkment city for surviving children?\n",
    "- What is the average fare of men that survived?\n",
    "- What is the average fare of women that survived?\n",
    "\n",
    "Use `pandas.eval` (or `pd.eval`, depending) and `DataFrame.eval()`/`DataFrame.query()` wherever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Impact of being alone on survival rates\n",
    "titanic['alone'] = titanic['who'] == 'male'\n",
    "survival_rates = titanic.groupby('alone')['survived'].mean().rename({True: 'Alone', False: 'Not Alone'})\n",
    "print(\"Impact of being alone on survival rates:\")\n",
    "print(survival_rates)\n",
    "\n",
    "# Most common embarkment city for surviving children\n",
    "common_embarkment_city = titanic.query('survived == 1 and age < 18')['embarked'].mode()[0]\n",
    "print(f\"\\nMost common embarkment city for surviving children: {common_embarkment_city}\")\n",
    "\n",
    "# Average fare of men that survived\n",
    "avg_fare_men_survived = titanic.query('survived == 1 and sex == \"male\"')['fare'].mean()\n",
    "print(f\"\\nAverage fare of men that survived: {avg_fare_men_survived:.2f}\")\n",
    "\n",
    "# Average fare of women that survived\n",
    "avg_fare_women_survived = titanic.query('survived == 1 and sex == \"female\"')['fare'].mean()\n",
    "print(f\"Average fare of women that survived: {avg_fare_women_survived:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "Type the following in a cell and run it:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from pathlib import Path\n",
    "def get_names():\n",
    "    if not Path('names.csv').exists():\n",
    "        names = pd.read_csv('https://belhavencs.nyc3.digitaloceanspaces.com/csc311/names.csv')\n",
    "        names.to_csv('names.csv', index=None)\n",
    "    else:\n",
    "        names = pd.read_csv('names.csv')\n",
    "    return names\n",
    "\n",
    "names = get_names()\n",
    "names.head()\n",
    "```\n",
    "\n",
    "The `names` DataFrame is a database of first names of children born since 1880. It has the following columns:\n",
    "\n",
    "Column | Description\n",
    ":-----:|:-----------\n",
    "**name** | First name given \n",
    "**gender** | Gender of the children with the name\n",
    "**births** | The number of children born with the name \n",
    "**year** | The year of birth \n",
    "\n",
    "Use the `names` DataFrame to do the following using the Pandas API:\n",
    "\n",
    "- Create a `rank` DataFrame where:\n",
    "    - Its index is the first names from `names`\n",
    "    - Its columns are a MultiIndex whose primary key is the decade and whose secondary keys are the following: \n",
    "        - number of births in the decade\n",
    "        - rank\n",
    "        - difference in rank from the last decade\n",
    "        - number of male births with the name\n",
    "        - number of female births with the name\n",
    "- Which names have dropped the most over a one decade period?\n",
    "- Which names have dropped the most over a five decade period?\n",
    "\n",
    "Use `pandas.eval` (or `pd.eval`, depending) and `DataFrame.eval()`/`DataFrame.query()` wherever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Here's the complete code snippet, consolidated without any separations:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to get names DataFrame\n",
    "def get_names():\n",
    "    if not Path('names.csv').exists():\n",
    "        names = pd.read_csv('https://belhavencs.nyc3.digitaloceanspaces.com/csc311/names.csv')\n",
    "        names.to_csv('names.csv', index=None)\n",
    "    else:\n",
    "        names = pd.read_csv('names.csv')\n",
    "    return names\n",
    "\n",
    "# Load names DataFrame\n",
    "names = get_names()\n",
    "\n",
    "# Create decade column\n",
    "names['decade'] = (names['year'] // 10) * 10\n",
    "\n",
    "# Create the rank DataFrame\n",
    "rank = (names.groupby(['decade', 'name'])\n",
    "        .agg(total_births=('births', 'sum'),\n",
    "             male_births=('births', lambda x: x[names.loc[x.index, 'gender'] == 'male'].sum()),\n",
    "             female_births=('births', lambda x: x[names.loc[x.index, 'gender'] == 'female'].sum()))\n",
    "        .reset_index())\n",
    "\n",
    "# Add rank and difference in rank\n",
    "rank['rank'] = rank.groupby('decade')['total_births'].rank(method='dense', ascending=False)\n",
    "rank['difference'] = rank.groupby('name')['rank'].diff().fillna(0)\n",
    "\n",
    "# Set MultiIndex\n",
    "rank.set_index(['name', 'decade'], inplace=True)\n",
    "rank = rank[['total_births', 'rank', 'difference', 'male_births', 'female_births']]\n",
    "\n",
    "# Names that dropped the most over one decade\n",
    "one_decade_drops = (rank['difference'].reset_index()\n",
    "                    .query('difference > 0')\n",
    "                    .groupby('name')['difference']\n",
    "                    .max()\n",
    "                    .reset_index())\n",
    "one_decade_drops = one_decade_drops.sort_values(by='difference', ascending=False)\n",
    "\n",
    "# Names that dropped the most over five decades\n",
    "five_decade_drops = (rank['difference'].reset_index()\n",
    "                     .groupby('name')['difference']\n",
    "                     .apply(lambda x: x.rolling(window=5).sum().min())\n",
    "                     .reset_index())\n",
    "five_decade_drops = five_decade_drops.sort_values(by='difference', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"Names that dropped the most over one decade:\")\n",
    "print(one_decade_drops.head())\n",
    "\n",
    "print(\"\\nNames that dropped the most over five decades:\")\n",
    "print(five_decade_drops.head())\n",
    "```\n",
    "\n",
    "This code is all together and ready to run, providing the desired analysis on the names dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "Using the `recipes` DataFrame from [Section 3.10](https://nbviewer.jupyter.org/urls/bitbucket.org/dogwynn/pythondatasciencehandbook/raw/master/notebooks/03.10-Working-With-Strings.ipynb#Example:-Recipe-Database), do the following:\n",
    "\n",
    "- Create a column, `prep_time` that is a `datetime.timedelta` object representation of the `prepTime` column\n",
    "- Create a column, `cook_time` that is a `datetime.timedelta` object representation of the `cookTime` column\n",
    "- Create a function that, given a list of [spices](https://nbviewer.jupyter.org/urls/bitbucket.org/dogwynn/pythondatasciencehandbook/raw/master/notebooks/03.10-Working-With-Strings.ipynb#A-simple-recipe-recommender), returns recipes sorted by total time (prep + cook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
